
\section{Preliminaries}

\subsection{Submanifolds}

Often in mathematics there is an obvious notion of a ``subobject'': given a structure on a set there is a simple way to restrict it to a subset, such that the subset can be said to have the same structure.
For example, the structure on a group is the identity, inversion, and multiplication; if there is a subset containing the identity and which is preserved under inversion and multiplication, then we have a subgroup.
Or for a topological space $X$, any subset $A$ has a topology given by intersection of open sets of $X$ with $A$.
The structures on the subset can often be characterised by the fact that they make the inclusion map $A \hookrightarrow X$ a structure preserving map (group homomorphism and continuous map respectively for the two examples).

In the case of manifolds however the definition of a submanifold is not as trivial and there are several notions that have strong claims for the title.
To complicate matters, the notion that is the most widely taught and used (embedded submanifold) is not the one that is most appropriate for Lie group theory (immersed submanifold).
Further, the two perspectives of the first paragraph, restriction and inclusion, each have their advantages.
It is perhaps more intuitive to work directly with a subset, but a manifold structure is an atlas, and it unpleasant to consider different atlases on the same subset.
The alternative is to work with inclusion maps.
Then different manifold structures of the subset are realised as inclusion maps from different manifolds with the same image.
% Our two main sources for this section are Sharpe and Warner.

\begin{definition}\textup{\cite[Def~1.27, Rem~1.33]{Warner1983},\cite[Defs~1.1.36,~1.1.40,~1.2.10]{Sharpe1997}} \\
Let $\phi : N \to M$ be a smooth map of manifolds.
\begin{enumerate}
\item 
$\phi$ is called an \emph{immersion} if $d\phi_p : T_pN \to T_{\phi(p)}M$ is injective at every point $p \in N$.
The pair $(N,\phi)$ is called an \emph{immersed manifold} in $M$.
% \item 
% $\phi$ is called a submersion if $d\phi_p : T_pN \to T_{\phi(p)}M$ is surjective at every point $p \in N$.
\item
If $\phi$ is an injective immersion then the pair is called an \emph{immersed submanifold}.
\item 
Two immersed submanifolds $(N_1,\phi_1)$ and $(N_2,\phi_2)$ are called \emph{equivalent} if there is a diffeomorphism $\varphi : N_1 \to N_2$ such that $\phi_1 = \phi_2 \circ \varphi$.
\item
If an injective immersion $\phi$ has the property that for every smooth map $f: S \to M$ with $f[S] \subset \phi[N]$ the map $\phi^{-1} \circ f : S \to N$ is smooth, then we call $\phi$ a \emph{weak embedding} and the pair a \emph{weakly embedded submanifold}.
\item
If an immersion $\phi$ is a homeomorphism from $N$ to $\phi(N)$, the latter with the subspace topology of $M$, then we call it an \emph{embedding} and the pair is called an \emph{embedded submanifold}.
\item
A continuous function between Hausdorff spaces is called \emph{proper} if the preimage of a compact set is always a compact set.
A proper immersion submanifold is called a \emph{proper submanifold}.
\end{enumerate}
\end{definition}

This is a lot of terminology, but it harmonises the definitions in Sharpe and Warner, see below table.
Note: Sharpe in Exercise~2.23 uses the term weakly embedded submanifold, but nowhere else explains it.
We do not understand the difference.
It is in fact a strict hierarchy: each type of submanifold is a subtype of the previous.

\begin{table}[h]
\begin{tabular}{l|l|l}
 & Sharpe & Warner \\ \hline
immersed manifold & immersed manifold & \\
immersed submanifold & & submanifold \\
weakly embedded submanifold & submanifold &  \\
embedded submanifold & regular submanifold & imbedding \\
\end{tabular}
\end{table}

These definitions are given in terms of a smooth map into $M$.
So the question from the other perspective is whether the manifold structure of $N$ is determined or can be recovered solely from the image $\phi[N]$.
There are simple examples that show that not even the topology of $N$ is determined for an immersed submanifold: consider the subset $\{x^2 = y^2\} \subset \bbR^2$.
We can split this into a line and two rays in two ways.
Therefore immersed submanifolds must always be given with the immersion $\phi$.

For weakly embedded submanifolds, we can determine $N$ from the image.
Let $N' = \phi[N]$.
Given a chart $\varphi: U \subset M \to \bbR^m$, the connected components of $N'\cap U$ are called plaques.
The intersection of open sets of $M$ with plaques gives $N'$ the \emph{submanifold topology}.
In general the submanifold topology is finer (has more open sets) than the subspace topology~\cite[Def~1.2.4]{Sharpe1997}.
% TODO: picture
For any plaque $W$, if $\varphi(W)$ lies in an $n$-dimensional affine subspace of $\bbR^m$ then we call the plaque $W$ flat and $\varphi|_W$ a plaque chart of $W$.
If there is a collection of charts of $M$ that cover $\bar{N'}$ such that all plaques are flat, then we have constructed an atlas for $N'$.
If $\phi$ is a weak embedding then this is always the case, and this manifold structure on $N'$ makes $\phi$ a diffeomorphism~\cite[Thm~1.2.7]{Sharpe1997}.
For this reason, we tend to identify $N$ and $N'$ and treat $\phi$ as the inclusion map of the subset.

The difference between weakly embedded and embedded is that there is a covering of $N'$ by open sets of $M$ such that each chart has a single flat plaque.
For embedded submanifolds the subspace and submanifold topologies coincide~\cite[Prop~1.2.9]{Sharpe1997}.
The image of $\phi : (0,\infty) \to \bbR^2, \phi(t) = (1-e^{-t})(\cos t, \sin t)$ is a weakly embedded submanifold that is not an embedded submanifold, 
TODO: I'm confused. Sharpe draws a picture of this spiral, but the definition of regular submanifold doesn't require the charts to cover $\bar{N'}$, which is meant to be the main obstacle? Is there no flat plaque for this?

Finally, by \cite[Thm~1.2.11]{Sharpe1997} proper submanifolds are automatically embedded, so we have a strict hierarchy of conditions.
The standard example of an embedded submanifold that is not proper is $(0,1) \subset \bbR$.
We see that a sequence in $N$ may converge to a point of $M\setminus N$.

These constructions, mostly from Sharpe, answer the question of how to endow a subset with a manifold structure.
There is the possibility however that there are different constructions.
Warner addresses these concerns with the following theorem: 
\begin{theorem}\label{thm:submanifolds}
\textup{\cite[Remark~1.33]{Warner1983}}
\begin{enumerate}
\item Let $M$ be a manifold and $A$ a subset of $M$. Fix a topology on $A$. Then there is at most one manifold structure on $A$ such that $(A,\iota)$ is an immersed submanifold of $M$, where $\iota$ is the inclusion map.
\item Again let $A$ be a subset of $M$. If in the subspace topology, $A$ has a manifold structure such that $(A,\iota)$ is an immersed submanifold of $M$, then it is the unique such manifold structure.
\end{enumerate}
\end{theorem}

\subsection{Distributions}

It is common in a course on manifolds to study vector fields and their integral curves.
The key local result is
\begin{theorem}[Picard-Lindelöff]
Let $F : J \times U \subset \bbR\times\bbR^n \to \bbR^n$ be a smooth time-dependent vector field. 
Assume $0 \in J$. 
Consider $u : \bbR \to U$ the system of ODEs $u'(t) = F(t,u(t))$.
For any $c \in U$ there exists a $\varepsilon > 0$ such that there is a unique solution smooth solution on $(-\varepsilon,\varepsilon)$ with $u(0) = c$.
Moreover, for any $p \in U$ there is an open neighbourhood $p \in V \subset U$, $\varepsilon > 0$ and smooth map $u : (-\varepsilon,\varepsilon) \times V \to U$ such that $u(\dot,c)$ is the unique solution with initial condition $c$.
\\\textup{\cite[Theorem~2.1.1]{Sharpe1997}}\cite[Theorem~1.2.1]{Ivey}
\end{theorem}

If one has a smooth vector field on a manifold, then this theorem provides for the existence of integral curves of the vector field in every coordinate chart, and uniqueness means that they can be patched together to give unique maximal integral curves through every point.

We will need a generalisation of this result that deals with multiple vector fields.
To motivate why this is geometrically interesting and not just generalisation for its own sake, consider a submanifold $N$ inside $M$.
At each point $p \in N$ we can consider the vector subspace $T_pN \subset T_pM$.
At least locally, we can describe these subspaces as the span of independent vector fields.
The natural question is the converse: given a set of independent vector fields on $M$, does there exist a submanifold $N$ whose tangent space is their span?
For a single vector field, the answer is affirmative, namely the integral curve.

\begin{definition}
An $r$-dimensional distribution $\mathcal{D}$ on $M$ is a choice of an $r$-dimensional subspace $\mathcal{D}_p$ of $T_p M$ at every point $p \in M$.
It is called smooth if every point has a neighbourhood and smooth vector fields $\{X_1, \dots, X_r \}$ that span the subspaces. 
It is called integrable if every point has a coordinate neighbourhood in which the distribution is spanned by coordinate vector fields.
\\
A set of vector fields is called algebraically involutive if their Lie brackets are contained in their span.
Two vector fields with the same span are either both algebraically involutive of neither is.
Therefore algebraically involutive is a property that is defined for Distributions.\\
A connected $r$-dimensional submanifold $N$ is called an integral manifold of $\mathcal{D}$ if at every point $T_pN = \mathcal{D}_p$.
\\\textup{\cite[2.2.1,.2.2.2,2.3.2]{Sharpe1997}}
\end{definition}

If a distribution is integrable, then every point has an integral submanifold through it, just by taking a coordinate plane in an appropriate chart.
The important theorem is Frobenius' theorem~\cite[2.4.1]{Sharpe1997}, which states a distribution is integrable if and only if it is algebraically involutive.
The proof inductively applies the Picard-Lindelöff theorem.

TODO: Example of spheres in $\bbR^3\setminus\{0\}$ showing that you might not have global vector fields.

There is also a formulation of Frobenius' theorem in terms of differential forms.
We can define the annihilator of a distribution as the algebraic ideal generated by the one-forms such that $\omega(v) = 0$ for all $v \in \mathcal{D}_p$.
By this we mean all $C^\infty$-linear combinations and wedge products.
Conversely, the kernel of an algebraic ideal of differential forms generated locally by $m-r$ independent one-forms is a distribution.
The theorem then says that $\mathcal{D}$ is integrable if and only if the ideal contains all its exterior derivatives (it is a differential ideal).
The proof comes down to the simple formula
\[
d\omega(X,Y) = X(\omega(Y)) - Y(\omega(X)) - \omega([X,Y]).
\]

TODO: Sharpe does foliations in general, and the argument look a lot like the arguments Warner uses for Lie subgroups.
I think it might be advantageous to follow Sharpe here and separate what is truly manifold theory from Lie theory.


TODO: I don't know where else to put this theorem.
There is a concern that if we have a smooth map $\psi: N \to M$ that happens to lie in a submanifold $P$, then is the induced map $\psi : N \to P$ given by restriction on the codomain a smooth map with respect to the manifold structure ono the submanifold.
The following theorem of Warner answers this affirmatively:
\begin{theorem}\label{theorem:cinfty}
\textup{\cite[1.62]{Warner1983}}\\
Suppose that $\psi \colon N \to M^d$ is $C^{\infty}$, that $(P^c,\varphi)$ is an integral manifold of an involutive distribution $\mathcal{D}$ on $M$, and that $\psi$ factors through $(P,\varphi)$, that is, $\psi[N] \subset \varphi[P]$. Let $\psi_0 : N \to P$ be the (unique) mapping such that $\varphi\circ \psi_0 = \psi$. Then $\psi_0$ is continuous and therefore $C^{\infty}$.
\end{theorem}

\subsection{Eigenvalues and Weights}

Eigenvalues and eigenvectors are ubiquitous in linear algebra.
If we are working over $\bbC$, then every linear endomorphism (linear map from a vector space $V$ to itself) has an eigenvalue (root of the characteristic polynomial) and every eigenvalue has an eigenvector $Av_\lambda = \lambda v_\lambda$.
If we can find a basis of eigenvectors, then with respect to this basis the linear operator is a diagonal matrix.
In general however, there may be fewer eigenvectors than the dimension of the vector space.
A standard result in linear algebra says that every matrix is conjugate to a matrix in Jordan normal form, unique up to reordering of the blocks.

Going further, we may ask what can be said of two linear endomorphisms $A,B$.
The key observation is to consider commuting operators.
If $A$ and $B$ commute then $B$ preserves the eigenspaces  eigenspaces of $A$:
\[
(A- \lambda I) (Bv) 
= B(A- \lambda I) v
= 0.
\]
Therefore $B$ restricts to an endomorphism on each of the eigenspaces of $A$.
Imposing different conditions on $A$ restricts the possible decompositions of $B$.
For example, if $A$ is diagonalizable (so $V$ decomposes as the direct sum of the eigenspaces of $A$) then on each eigenspace of $A$ we can choose a basis that puts $B$ into Jordan normal form.
Hence $A$ and $B$ can simultaneously conjugated to normal form.
Or if $A$ is diagonalizable and has no repeated eigenvalues, ie its eigenspaces are one dimensional, then these must also be eigenspaces of $B$.
Hence $A$ and $B$ are simultaneously diagonalizable.

This argument can be applied inductively to a finite set $\{A_1,\dots,A_k\}$ of pairwise commuting endomorphisms.
It also extends to a commuting family of operators $\mathcal{A} = \vspan\{A_1,\dots,A_k\}$, a linear subspace of $\End(V)$ such that all operators are pairwise commuting.
These are effectively equivalent, since a family is pairwise commuting if and only if a basis is pairwise commuting.
Likewise, $v$ is a simultaneous eigenvector for $\{A_1,\dots,A_k\}$ if and only if it is a simultaneous eigenvector for every operator of $\mathcal{A}$.
The eigenvalues are not completely independent:
\[
\lambda v
= Av 
= (a_1A_1 + \dots + a_kA_k)v
= a_1 \lambda_1 v + \dots + a_k \lambda_k v
= (a_1 \lambda_1 + \dots + a_k \lambda_k )v.
\]
We understand the eigenvalue of $v$ to be a linear function 
\[
\lambda : \mathcal{A} \to \mathbb{K}, 
\quad
\lambda(A) = a_1 \lambda_1 + \dots + a_k \lambda_k .
\]
Understood in this way, it is more common to call $\lambda$ a \emph{weight} of the commuting family $\mathcal{A}$, $v$ a \emph{weight vector}, and the set of vectors $v$ with $Av = \lambda(A)v$ the \emph{weight} space~\cite[Definition~A.14]{Hall2015}.

As an aside, the descriptor ``weight'' should probably replace ``eigen-'' even in the single operator case.
Consider an operator $A$ with a $2$-weight vector $v$ and a $3$-weight vector $w$.
Then of course $A(av+bw) = 2v + 3w$, which is a weighted sum.

We finish with an example.
Let $\mathcal{A}$ be the set of diagonal $n\times n$ matrices.
Then a basis for this family is $A_i = e_{ii}$, with $1$ at the $i$th position on the diagonal.
$e_i$ is a $1$-weight vector of $A_i$ while all vectors of $\vspan\{e_1,\dots,\hat{e}_i,\dots,e_n\}$ are $0$-weight (in the kernel).
These are all diagonal (in particular simultaneously diagonal) so there should be a basis of weight vectors.
Indeed, this is just the standard basis $\{e_1,\dots,e_n\}$.
The weight of $e_i$ is the linear form
\[
A = \operatorname{diag}(a_1,\dots,a_n) \mapsto a_i
\]
because $A e_i = a_i$.

